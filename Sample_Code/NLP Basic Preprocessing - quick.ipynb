{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to convert a list to string    \n",
    "# Function to convert  \n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"D:/Documents/PPCC/COM225/Week 4/Dream.txt\")\n",
    "X = df['sentiment'].tolist()\n",
    "def listToString(txt):     \n",
    "    # initialize an empty string \n",
    "    str1 = \"\"  \n",
    "    # traverse in the string   \n",
    "    for ele in txt:  \n",
    "        str1 += ele     \n",
    "    # return string   \n",
    "    return str1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.Five score years ago a great American in whose symbolic shadow we stand today signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of their captivity.But one hundred years later the Negro still is not free. One hundred years later the life of the Negro is still sadly crippled by the manacles of segregation and the chains of discrimination. One hundred years later the Negro lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later the Negro is still languished in the corners of American society and finds himself an exile in his own land. And so we've come here today to dramatize a shameful condition.In a sense we've come to our nation's capital to cash a check. When the architects of our republic wrote the magnificent words of the Constitution and the Declaration of Independence they were signing a promissory note to which every American was to fall heir. This note was a promise that all men yes black men as well as white men would be guaranteed the unalienable Rights of Life Liberty and the pursuit of Happiness. It is obvious today that America has defaulted on this promissory note insofar as her citizens of color are concerned. Instead of honoring this sacred obligation America has given the Negro people a bad check a check which has come back marked insufficient funds.But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. And so we've come to cash this check a check that will give us upon demand the riches of freedom and the security of justice.We have also come to this hallowed spot to remind America of the fierce urgency of Now. This is no time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism. Now is the time to make real the promises of democracy. Now is the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice. Now is the time to lift our nation from the quicksands of racial injustice to the solid rock of brotherhood. Now is the time to make justice a reality for all of God's children.It would be fatal for the nation to overlook the urgency of the moment. This sweltering summer of the Negro's legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end but a beginning. And those who hope that the Negro needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual. And there will be neither rest nor tranquility in America until the Negro is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.But there is something that I must say to my people who stand on the warm threshold which leads into the palace of justice: In the process of gaining our rightful place we must not be guilty of wrongful deeds. Let us not seek to satisfy our thirst for freedom by drinking from the cup of bitterness and hatred. We must forever conduct our struggle on the high plane of dignity and discipline. We must not allow our creative protest to degenerate into physical violence. Again and again we must rise to the majestic heights of meeting physical force with soul force.The marvelous new militancy which has engulfed the Negro community must not lead us to a distrust of all white people for many of our white brothers as evidenced by their presence here today have come to realize that their destiny is tied up with our destiny. And they have come to realize that their freedom is inextricably bound to our freedom.We cannot walk alone.And as we walk we must make the pledge that we shall always march ahead.We cannot turn back.There are those who are asking the devotees of civil rights When will you be satisfied? We can never be satisfied as long as the Negro is the victim of the unspeakable horrors of police brutality. We can never be satisfied as long as our bodies heavy with the fatigue of travel cannot gain lodging in the motels of the highways and the hotels of the cities. We cannot be satisfied as long as the negro's basic mobility is from a smaller ghetto to a larger one. We can never be satisfied as long as our children are stripped of their self-hood and robbed of their dignity by signs stating: For Whites Only. We cannot be satisfied as long as a Negro in Mississippi cannot vote and a Negro in New York believes he has nothing for which to vote. No no we are not satisfied and we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream.I am not unmindful that some of you have come here out of great trials and tribulations. Some of you have come fresh from narrow jail cells. And some of you have come from areas where your quest quest for freedom left you battered by the storms of persecution and staggered by the winds of police brutality. You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive. Go back to Mississippi go back to Alabama go back to South Carolina go back to Georgia go back to Louisiana go back to the slums and ghettos of our northern cities knowing that somehow this situation can and will be changed.Let us not wallow in the valley of despair I say to you today my friends.And so even though we face the difficulties of today and tomorrow I still have a dream. It is a dream deeply rooted in the American dream.I have a dream that one day this nation will rise up and live out the true meaning of its creed: We hold these truths to be self-evident that all men are created equal.I have a dream that one day on the red hills of Georgia the sons of former slaves and the sons of former slave owners will be able to sit down together at the table of brotherhood.I have a dream that one day even the state of Mississippi a state sweltering with the heat of injustice sweltering with the heat of oppression will be transformed into an oasis of freedom and justice.I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.I have a dream todayI have a dream that one day down in Alabama with its vicious racists with its governor having his lips dripping with the words of interposition and nullification one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.I have a dream todayI have a dream that one day every valley shall be exalted and every hill and mountain shall be made low the rough places will be made plain and the crooked places will be made straight; and the glory of the Lord shall be revealed and all flesh shall see it together.This is our hope and this is the faith that I go back to the South with.With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together to pray together to struggle together to go to jail together to stand up for freedom together knowing that we will be free one day.And this will be the day -- this will be the day when all of God's children will be able to sing with new meaning:My country 'tis of thee sweet land of liberty of thee I sing. Land where my fathers died land of the Pilgrim's pride    From every mountainside let freedom ring And if America is to be a great nation this must become true.And so let freedom ring from the prodigious hilltops of New Hampshire.Let freedom ring from the mighty mountains of New York.Let freedom ring from the heightening Alleghenies of Pennsylvania.Let freedom ring from the snow-capped Rockies of Colorado.Let freedom ring from the curvaceous slopes of California.But not only that:Let freedom ring from Stone Mountain of Georgia.Let freedom ring from Lookout Mountain of Tennessee.Let freedom ring from every hill and molehill of Mississippi.From every mountainside let freedom ring.And when this happens and when we allow freedom ring when we let it ring from every village and every hamlet from every state and every city we will be able to speed up that day when all of God's children black men and white men Jews and Gentiles Protestants and Catholics will be able to join hands and sing in the words of the old Negro spiritual:Free at last Free at lastThank God Almighty we are free at last\n"
     ]
    }
   ],
   "source": [
    "# Generate Raw Text     \n",
    "txt = X \n",
    "text = listToString(txt)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import string\n",
    " \n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # convert to lowercase\n",
    "    doc = doc.lower()\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 3]  \n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'join', 'today', 'history', 'greatest', 'demonstration', 'freedom', 'history', 'nationfive', 'score', 'years', 'great', 'american', 'whose', 'symbolic', 'shadow', 'stand', 'today', 'signed', 'emancipation', 'proclamation', 'momentous', 'decree', 'came', 'great', 'beacon', 'light', 'hope', 'millions', 'negro', 'slaves', 'seared', 'flames', 'withering', 'injustice', 'came', 'joyous', 'daybreak', 'long', 'night', 'captivitybut', 'hundred', 'years', 'later', 'negro', 'still', 'free', 'hundred', 'years', 'later', 'life', 'negro', 'still', 'sadly', 'crippled', 'manacles', 'segregation', 'chains', 'discrimination', 'hundred', 'years', 'later', 'negro', 'lives', 'lonely', 'island', 'poverty', 'midst', 'vast', 'ocean', 'material', 'prosperity', 'hundred', 'years', 'later', 'negro', 'still', 'languished', 'corners', 'american', 'society', 'finds', 'exile', 'land', 'weve', 'come', 'today', 'dramatize', 'shameful', 'conditionin', 'sense', 'weve', 'come', 'nations', 'capital', 'cash', 'check', 'architects', 'republic', 'wrote', 'magnificent', 'words', 'constitution', 'declaration', 'independence', 'signing', 'promissory', 'note', 'every', 'american', 'fall', 'heir', 'note', 'promise', 'black', 'well', 'white', 'would', 'guaranteed', 'unalienable', 'rights', 'life', 'liberty', 'pursuit', 'happiness', 'obvious', 'today', 'america', 'defaulted', 'promissory', 'note', 'insofar', 'citizens', 'color', 'concerned', 'instead', 'honoring', 'sacred', 'obligation', 'america', 'given', 'negro', 'people', 'check', 'check', 'come', 'back', 'marked', 'insufficient', 'fundsbut', 'refuse', 'believe', 'bank', 'justice', 'bankrupt', 'refuse', 'believe', 'insufficient', 'funds', 'great', 'vaults', 'opportunity', 'nation', 'weve', 'come', 'cash', 'check', 'check', 'give', 'upon', 'demand', 'riches', 'freedom', 'security', 'justicewe', 'also', 'come', 'hallowed', 'spot', 'remind', 'america', 'fierce', 'urgency', 'time', 'engage', 'luxury', 'cooling', 'take', 'tranquilizing', 'drug', 'gradualism', 'time', 'make', 'real', 'promises', 'democracy', 'time', 'rise', 'dark', 'desolate', 'valley', 'segregation', 'sunlit', 'path', 'racial', 'justice', 'time', 'lift', 'nation', 'quicksands', 'racial', 'injustice', 'solid', 'rock', 'brotherhood', 'time', 'make', 'justice', 'reality', 'gods', 'childrenit', 'would', 'fatal', 'nation', 'overlook', 'urgency', 'moment', 'sweltering', 'summer', 'negros', 'legitimate', 'discontent', 'pass', 'invigorating', 'autumn', 'freedom', 'equality', 'nineteen', 'sixtythree', 'beginning', 'hope', 'negro', 'needed', 'blow', 'steam', 'content', 'rude', 'awakening', 'nation', 'returns', 'business', 'usual', 'neither', 'rest', 'tranquility', 'america', 'negro', 'granted', 'citizenship', 'rights', 'whirlwinds', 'revolt', 'continue', 'shake', 'foundations', 'nation', 'bright', 'justice', 'emergesbut', 'something', 'must', 'people', 'stand', 'warm', 'threshold', 'leads', 'palace', 'justice', 'process', 'gaining', 'rightful', 'place', 'must', 'guilty', 'wrongful', 'deeds', 'seek', 'satisfy', 'thirst', 'freedom', 'drinking', 'bitterness', 'hatred', 'must', 'forever', 'conduct', 'struggle', 'high', 'plane', 'dignity', 'discipline', 'must', 'allow', 'creative', 'protest', 'degenerate', 'physical', 'violence', 'must', 'rise', 'majestic', 'heights', 'meeting', 'physical', 'force', 'soul', 'forcethe', 'marvelous', 'militancy', 'engulfed', 'negro', 'community', 'must', 'lead', 'distrust', 'white', 'people', 'many', 'white', 'brothers', 'evidenced', 'presence', 'today', 'come', 'realize', 'destiny', 'tied', 'destiny', 'come', 'realize', 'freedom', 'inextricably', 'bound', 'freedomwe', 'cannot', 'walk', 'aloneand', 'walk', 'must', 'make', 'pledge', 'shall', 'always', 'march', 'aheadwe', 'cannot', 'turn', 'backthere', 'asking', 'devotees', 'civil', 'rights', 'satisfied', 'never', 'satisfied', 'long', 'negro', 'victim', 'unspeakable', 'horrors', 'police', 'brutality', 'never', 'satisfied', 'long', 'bodies', 'heavy', 'fatigue', 'travel', 'cannot', 'gain', 'lodging', 'motels', 'highways', 'hotels', 'cities', 'cannot', 'satisfied', 'long', 'negros', 'basic', 'mobility', 'smaller', 'ghetto', 'larger', 'never', 'satisfied', 'long', 'children', 'stripped', 'selfhood', 'robbed', 'dignity', 'signs', 'stating', 'whites', 'cannot', 'satisfied', 'long', 'negro', 'mississippi', 'cannot', 'vote', 'negro', 'york', 'believes', 'nothing', 'vote', 'satisfied', 'satisfied', 'justice', 'rolls', 'like', 'waters', 'righteousness', 'like', 'mighty', 'streami', 'unmindful', 'come', 'great', 'trials', 'tribulations', 'come', 'fresh', 'narrow', 'jail', 'cells', 'come', 'areas', 'quest', 'quest', 'freedom', 'left', 'battered', 'storms', 'persecution', 'staggered', 'winds', 'police', 'brutality', 'veterans', 'creative', 'suffering', 'continue', 'work', 'faith', 'unearned', 'suffering', 'redemptive', 'back', 'mississippi', 'back', 'alabama', 'back', 'south', 'carolina', 'back', 'georgia', 'back', 'louisiana', 'back', 'slums', 'ghettos', 'northern', 'cities', 'knowing', 'somehow', 'situation', 'changedlet', 'wallow', 'valley', 'despair', 'today', 'friendsand', 'even', 'though', 'face', 'difficulties', 'today', 'tomorrow', 'still', 'dream', 'dream', 'deeply', 'rooted', 'american', 'dreami', 'dream', 'nation', 'rise', 'live', 'true', 'meaning', 'creed', 'hold', 'truths', 'selfevident', 'created', 'equali', 'dream', 'hills', 'georgia', 'sons', 'former', 'slaves', 'sons', 'former', 'slave', 'owners', 'able', 'together', 'table', 'brotherhoodi', 'dream', 'even', 'state', 'mississippi', 'state', 'sweltering', 'heat', 'injustice', 'sweltering', 'heat', 'oppression', 'transformed', 'oasis', 'freedom', 'justicei', 'dream', 'four', 'little', 'children', 'live', 'nation', 'judged', 'color', 'skin', 'content', 'characteri', 'dream', 'todayi', 'dream', 'alabama', 'vicious', 'racists', 'governor', 'lips', 'dripping', 'words', 'interposition', 'nullification', 'right', 'alabama', 'little', 'black', 'boys', 'black', 'girls', 'able', 'join', 'hands', 'little', 'white', 'boys', 'white', 'girls', 'sisters', 'brothersi', 'dream', 'todayi', 'dream', 'every', 'valley', 'shall', 'exalted', 'every', 'hill', 'mountain', 'shall', 'made', 'rough', 'places', 'made', 'plain', 'crooked', 'places', 'made', 'straight', 'glory', 'lord', 'shall', 'revealed', 'flesh', 'shall', 'togetherthis', 'hope', 'faith', 'back', 'south', 'withwith', 'faith', 'able', 'mountain', 'despair', 'stone', 'hope', 'faith', 'able', 'transform', 'jangling', 'discords', 'nation', 'beautiful', 'symphony', 'brotherhood', 'faith', 'able', 'work', 'together', 'pray', 'together', 'struggle', 'together', 'jail', 'together', 'stand', 'freedom', 'together', 'knowing', 'free', 'dayand', 'gods', 'children', 'able', 'sing', 'meaningmy', 'country', 'thee', 'sweet', 'land', 'liberty', 'thee', 'sing', 'land', 'fathers', 'died', 'land', 'pilgrims', 'pride', 'every', 'mountainside', 'freedom', 'ring', 'america', 'great', 'nation', 'must', 'become', 'trueand', 'freedom', 'ring', 'prodigious', 'hilltops', 'hampshirelet', 'freedom', 'ring', 'mighty', 'mountains', 'yorklet', 'freedom', 'ring', 'heightening', 'alleghenies', 'pennsylvanialet', 'freedom', 'ring', 'snowcapped', 'rockies', 'coloradolet', 'freedom', 'ring', 'curvaceous', 'slopes', 'californiabut', 'thatlet', 'freedom', 'ring', 'stone', 'mountain', 'georgialet', 'freedom', 'ring', 'lookout', 'mountain', 'tennesseelet', 'freedom', 'ring', 'every', 'hill', 'molehill', 'mississippifrom', 'every', 'mountainside', 'freedom', 'ringand', 'happens', 'allow', 'freedom', 'ring', 'ring', 'every', 'village', 'every', 'hamlet', 'every', 'state', 'every', 'city', 'able', 'speed', 'gods', 'children', 'black', 'white', 'jews', 'gentiles', 'protestants', 'catholics', 'able', 'join', 'hands', 'sing', 'words', 'negro', 'spiritualfree', 'last', 'free', 'lastthank', 'almighty', 'free', 'last']\n"
     ]
    }
   ],
   "source": [
    "# Generate Clean Text\n",
    "tokens = clean_doc(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create vocabulary of all the words in the data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(df['sentiment'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 36)\t1\n",
      "  (0, 73)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 53)\t1\n",
      "  (1, 73)\t1\n",
      "  (1, 82)\t1\n",
      "  (1, 29)\t2\n",
      "  (1, 4)\t1\n",
      "  (1, 68)\t1\n",
      "  (1, 32)\t1\n",
      "  (1, 54)\t1\n",
      "  (1, 66)\t1\n",
      "  (1, 33)\t1\n",
      "  (1, 22)\t1\n",
      "  (1, 45)\t1\n",
      "  (2, 73)\t1\n",
      "  (2, 82)\t4\n",
      "  (2, 4)\t1\n",
      "  (2, 54)\t4\n",
      "  (2, 24)\t1\n",
      "  (2, 42)\t1\n",
      "  (2, 62)\t1\n",
      "  (2, 39)\t1\n",
      "  (2, 77)\t1\n",
      "  (2, 14)\t1\n",
      "  :\t:\n",
      "  (37, 59)\t1\n",
      "  (38, 25)\t1\n",
      "  (38, 40)\t1\n",
      "  (38, 52)\t1\n",
      "  (38, 59)\t1\n",
      "  (39, 36)\t1\n",
      "  (39, 25)\t1\n",
      "  (39, 54)\t1\n",
      "  (39, 80)\t1\n",
      "  (39, 48)\t2\n",
      "  (39, 5)\t1\n",
      "  (39, 79)\t1\n",
      "  (39, 28)\t1\n",
      "  (39, 11)\t1\n",
      "  (39, 18)\t1\n",
      "  (39, 40)\t1\n",
      "  (39, 2)\t1\n",
      "  (39, 0)\t2\n",
      "  (39, 69)\t1\n",
      "  (39, 30)\t1\n",
      "  (39, 65)\t1\n",
      "  (39, 59)\t2\n",
      "  (40, 24)\t2\n",
      "  (41, 24)\t1\n",
      "  (41, 28)\t1\n"
     ]
    }
   ],
   "source": [
    "print(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use LDA to create topics \n",
    "# Also gives probability distribution for each word in our vocabulary for each topic\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "justice\n",
      "brotherhood\n",
      "nation\n",
      "despair\n",
      "continue\n",
      "nation\n",
      "say\n",
      "police\n",
      "today\n",
      "ring\n"
     ]
    }
   ],
   "source": [
    "# Randomly fetches 10 words from the vocabulary\n",
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the components_ attribute and pass a 0 index as the value\n",
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the indexes of the 10 words with the highest probabilities\n",
    "top_topic_words = first_topic.argsort()[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mississippi\n",
      "freedom\n",
      "sweltering\n",
      "state\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the value of the words from the count_vect object\n",
    "for i in top_topic_words:\n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words for topic #0:\n",
      "['injustice', 'mississippi', 'freedom', 'sweltering', 'state']\n",
      "\n",
      "\n",
      "Top 5 words for topic #1:\n",
      "['great', 'today', 'let', 'negro', 'long']\n",
      "\n",
      "\n",
      "Top 5 words for topic #2:\n",
      "['negro', 'come', 'let', 'ring', 'freedom']\n",
      "\n",
      "\n",
      "Top 5 words for topic #3:\n",
      "['little', 'shall', 'able', 'day', 'dream']\n",
      "\n",
      "\n",
      "Top 5 words for topic #4:\n",
      "['come', 'america', 'check', 'justice', 'nation']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the 10 words with highest probabilities for all the five topics\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 5 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-5:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column to the original data frame that will store the topic for the text\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column for topic in the data frame\n",
    "# Also assign the topic value to each row in the column\n",
    "df['sentiment'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "0          4\n",
       "1          1\n",
       "2          2\n",
       "3          4\n",
       "4          4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1     1\n",
       "2     2\n",
       "3     4\n",
       "4     4\n",
       "5     4\n",
       "6     4\n",
       "7     1\n",
       "8     2\n",
       "9     1\n",
       "10    1\n",
       "11    0\n",
       "12    1\n",
       "13    2\n",
       "14    1\n",
       "15    3\n",
       "16    3\n",
       "17    3\n",
       "18    0\n",
       "19    3\n",
       "20    3\n",
       "21    3\n",
       "22    3\n",
       "23    3\n",
       "24    2\n",
       "25    2\n",
       "26    3\n",
       "27    2\n",
       "28    0\n",
       "29    2\n",
       "30    2\n",
       "31    2\n",
       "32    2\n",
       "33    2\n",
       "34    0\n",
       "35    2\n",
       "36    2\n",
       "37    2\n",
       "38    2\n",
       "39    3\n",
       "40    2\n",
       "41    2\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-ea55c5186550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mwordcloud0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# for bank_service\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#print(prodct_group)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#print('sentiment')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m         \"\"\"\n\u001b[1;32m--> 619\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \"\"\"\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mr\"\\w[\\w']+\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;31m# remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "wordcloud0 = WordCloud().generate(new_df) # for bank_service\n",
    "#print(prodct_group)\n",
    "#print('sentiment')\n",
    "plt.imshow(wordcloud0, interpolation = 'bilinear')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-a0247f4d536e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m         \"\"\"\n\u001b[1;32m--> 619\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \"\"\"\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mr\"\\w[\\w']+\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;31m# remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "WordCloud().generate(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Documents/PPCC/COM225/Week 4/Dream.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     I am happy to join with you today in what will...\n",
       "1     Five score years ago a great American in whose...\n",
       "2     But one hundred years later the Negro still is...\n",
       "3     In a sense we've come to our nation's capital ...\n",
       "4     But we refuse to believe that the bank of just...\n",
       "5     We have also come to this hallowed spot to rem...\n",
       "6     It would be fatal for the nation to overlook t...\n",
       "7     But there is something that I must say to my p...\n",
       "8     The marvelous new militancy which has engulfed...\n",
       "9                                 We cannot walk alone.\n",
       "10    And as we walk we must make the pledge that we...\n",
       "11                                 We cannot turn back.\n",
       "12    There are those who are asking the devotees of...\n",
       "13    I am not unmindful that some of you have come ...\n",
       "14    Let us not wallow in the valley of despair I s...\n",
       "15    And so even though we face the difficulties of...\n",
       "16    I have a dream that one day this nation will r...\n",
       "17    I have a dream that one day on the red hills o...\n",
       "18    I have a dream that one day even the state of ...\n",
       "19    I have a dream that my four little children wi...\n",
       "20                                 I have a dream today\n",
       "21    I have a dream that one day down in Alabama wi...\n",
       "22                                 I have a dream today\n",
       "23    I have a dream that one day every valley shall...\n",
       "24    This is our hope and this is the faith that I ...\n",
       "25    With this faith we will be able to hew out of ...\n",
       "26    And this will be the day -- this will be the d...\n",
       "27    My country 'tis of thee sweet land of liberty ...\n",
       "28    And if America is to be a great nation this mu...\n",
       "29    And so let freedom ring from the prodigious hi...\n",
       "30    Let freedom ring from the mighty mountains of ...\n",
       "31    Let freedom ring from the heightening Alleghen...\n",
       "32    Let freedom ring from the snow-capped Rockies ...\n",
       "33    Let freedom ring from the curvaceous slopes of...\n",
       "34                                   But not only that:\n",
       "35     Let freedom ring from Stone Mountain of Georgia.\n",
       "36    Let freedom ring from Lookout Mountain of Tenn...\n",
       "37    Let freedom ring from every hill and molehill ...\n",
       "38            From every mountainside let freedom ring.\n",
       "39    And when this happens and when we allow freedo...\n",
       "40                            Free at last Free at last\n",
       "41               Thank God Almighty we are free at last\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Five score years ago a great American in whose symbolic shadow we stand today signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of their captivity.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
